{
    "docs": [
        {
            "location": "/",
            "text": "Leela\n\n\nIntroduction\n\n\nLeela started as a time-series engine, very similar to graphite \n1\n\nbut with less features, tailored for our needs. We found it hard to\nscale graphite at the time and figure that using cassandra would make\nit a lot easier to scale up and cope with our load. Back then we were\ncollecting mostly server metrics like cpu, memory and disk.\n\n\nAfter a while we figure we also wanted to store more information about\nour datacenter. Like the relationships a machine or switch may\nhave. For instance, in what switch a given network card is connected\nto.\n\n\nLeela then evolved into a property-graph engine. It continue to be a\ntime-series storage but we now could create vertexes and connects them\nto each other.\n\n\nThis allowed us to store complex data, like the relationships we have\nin our datacenter:\n\n\n      o cpu-usage [time-series]\n      |  \n      |  o hwinfo [json-data]\n      |  |\n   +---------+     +-----+            +--------+\n   | machine |-----| nic |----------->| switch |\n   +---------+     +-----+            +--------+\n                                          |\n           +------------+    +-----+      |\n           | datacenter |<---| rak |<-----+\n           +------------+    +-----+\n\n\n\n\nIt is an ever-evolving system and we are continuously working on\nit. New features are planned and we are working hard to improve the\ndocumentation as fast as we can.\n\n\nThe Documentation\n\n\nThis section describes how the documentation has been organized. There\nare three major sections, Development, Operations and Users. Each\nsection covers a given aspect of the system from that perspective.\n\n\nOrthogonal to those sections there are the various modules that\ncomprise Leela.\n\n\n\n\n\n\n\n\nclient libraries\n\n\nbackend modules\n\n\nfrontend\n\n\n\n\n\n\n\n\n\n\nlibleela\n\n\nwarpgrep\n\n\nwarpserver\n\n\n\n\n\n\nlibleela-ruby\n\n\nblackbox\n\n\nwebleela\n\n\n\n\n\n\nlibleela-python\n\n\n\n\n\n\n\n\n\n\n\n\nAll client libraries are built on top of \nlibleela\n. \nLibleela\n is\nwritten in C and the other languages creates a module on top of that\nlibrary.\n\n\nBlackbox\n and \nwarpgrep\n are internal modules, the user usually don't\nneed to interact with them. They are used by \nwarpserver\n. The former\nprovides access to the storage engine whereas the later allows users\nto monitor queries in real-time.\n\n\nWarpserver\n and \nwebleela\n are the frontends. They provide a \nZMQ\n\n interface and an \nHTTP\n interface, respectively.\n\n\nDevelopment\n\n\nThe audience is software developers of ones interested in contributing\nor learning about Leela internals.\n\n\n\n\nEnvironment\n\n\n\n\nOperations\n\n\nThe audience is system administrators or ones interested in\ninstalling, maintaining and tuning a Leela cluster.\n\n\n\n\n\n\nPackaging Leela\n\n\n\n\n\n\nCassandra\n\n\n\n\n\n\nConsul\n\n\n\n\n\n\nRedis\n\n\n\n\n\n\nInstalling Leela\n\n\n\n\n\n\nUser Guide\n\n\nFor the ones interested in using a Leela cluster.\n\n\n\n\n\n\nLeela Query Language\n\n\n\n\n\n\nHTTP Interface\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://graphite.readthedocs.org\u00a0\n\u21a9",
            "title": "Home"
        },
        {
            "location": "/#leela",
            "text": "",
            "title": "Leela"
        },
        {
            "location": "/#introduction",
            "text": "Leela started as a time-series engine, very similar to graphite  1 \nbut with less features, tailored for our needs. We found it hard to\nscale graphite at the time and figure that using cassandra would make\nit a lot easier to scale up and cope with our load. Back then we were\ncollecting mostly server metrics like cpu, memory and disk.  After a while we figure we also wanted to store more information about\nour datacenter. Like the relationships a machine or switch may\nhave. For instance, in what switch a given network card is connected\nto.  Leela then evolved into a property-graph engine. It continue to be a\ntime-series storage but we now could create vertexes and connects them\nto each other.  This allowed us to store complex data, like the relationships we have\nin our datacenter:        o cpu-usage [time-series]\n      |  \n      |  o hwinfo [json-data]\n      |  |\n   +---------+     +-----+            +--------+\n   | machine |-----| nic |----------->| switch |\n   +---------+     +-----+            +--------+\n                                          |\n           +------------+    +-----+      |\n           | datacenter |<---| rak |<-----+\n           +------------+    +-----+  It is an ever-evolving system and we are continuously working on\nit. New features are planned and we are working hard to improve the\ndocumentation as fast as we can.",
            "title": "Introduction"
        },
        {
            "location": "/#the-documentation",
            "text": "This section describes how the documentation has been organized. There\nare three major sections, Development, Operations and Users. Each\nsection covers a given aspect of the system from that perspective.  Orthogonal to those sections there are the various modules that\ncomprise Leela.     client libraries  backend modules  frontend      libleela  warpgrep  warpserver    libleela-ruby  blackbox  webleela    libleela-python       All client libraries are built on top of  libleela .  Libleela  is\nwritten in C and the other languages creates a module on top of that\nlibrary.  Blackbox  and  warpgrep  are internal modules, the user usually don't\nneed to interact with them. They are used by  warpserver . The former\nprovides access to the storage engine whereas the later allows users\nto monitor queries in real-time.  Warpserver  and  webleela  are the frontends. They provide a  ZMQ \n interface and an  HTTP  interface, respectively.  Development  The audience is software developers of ones interested in contributing\nor learning about Leela internals.   Environment   Operations  The audience is system administrators or ones interested in\ninstalling, maintaining and tuning a Leela cluster.    Packaging Leela    Cassandra    Consul    Redis    Installing Leela    User Guide  For the ones interested in using a Leela cluster.    Leela Query Language    HTTP Interface        http://graphite.readthedocs.org\u00a0 \u21a9",
            "title": "The Documentation"
        },
        {
            "location": "/user/http-interface/",
            "text": "LEELA HTTP INTERFACE\n\n\nLeela has an HTTP interface that provides a RESTful API to query\ndata. Notice at this point this API is read only.\n\n\n/v2\n\n\nThis entrypoint allows you to issue lql queries to leela.\n\n\nQuery string:\n\n\n\n\nq\n      : The well-defined lql query\n\n\nformat\n : json|text [default: json]\n\n\n\n\nExamples:\n\n\n/v2?q=using (leela::sandbox) guid (machine::warp0013);\n\n\n\n/v2/kind/name\n\n\nThis entrypoint issues a \npath\n command. It retrieves all edges a\ngiven vertex may have.\n\n\nQuery string:\n\n\n\n\ntree\n   : the namespace;\n\n\nformat\n : json|text [default: json]\n\n\n\n\nExamples:\n\n\n  /v2/machine/warp0013?tree=leela::sandbox\n\n\n\n\nN.B.: Remember to encode properly the query parameters!!!\n\n\n/v2/kind/name/label1/label2/.../labelN\n\n\nThis entrypoint issuse a \npath\n command. It retrieves all edges a\ngiven vertex may have. This is the same as the previous endpoint but\nyou can provide some labels to navigate further down in the graph.\n\n\nExamples:\n\n\n  /v2/machine/warp0013/server/nic?tree=leela::sandbox\n\n\n\n\nThe above query issues the lql command:\n\n\n  using (leela::sandbox) path GUID -[server]> () -[nic]> ();\n\n\n\n\nThe GUID is the guid of \nmachine::warp0013\n.\n\n\nQuery string\n\n\n\n\ntree\n   : the namespace;\n\n\nformat\n : json|text [default: json]\n\n\n\n\n/v2/last/*\n\n\nThis entrypoint returns the last known value of a metric up to\n24h. Notice this is read from a cache and as such it may may return\neverything that exists in the database. That said, it is a good way to\nfetch data from multiple sources efficently.\n\n\nParameters:\n\n\n\n\nattr\n   : The attribute to retrieve [eg: \ncpu-0/cpu-idle\n]. Notice you\n  can use also use glob syntax;\n\n\ntree\n   : the namespace;\n\n\nformat\n : json|text [default: json]\n\n\n\n\nThe following example retrieves everything from \nmachine::warp0013\n.\n\n\n  /v2/last/machine/warp0013?tree=locaweb::sandbox&format=text&attr=*",
            "title": "Http interface"
        },
        {
            "location": "/user/http-interface/#leela-http-interface",
            "text": "Leela has an HTTP interface that provides a RESTful API to query\ndata. Notice at this point this API is read only.",
            "title": "LEELA HTTP INTERFACE"
        },
        {
            "location": "/user/http-interface/#v2",
            "text": "This entrypoint allows you to issue lql queries to leela.  Query string:   q       : The well-defined lql query  format  : json|text [default: json]   Examples:  /v2?q=using (leela::sandbox) guid (machine::warp0013);",
            "title": "/v2"
        },
        {
            "location": "/user/http-interface/#v2kindname",
            "text": "This entrypoint issues a  path  command. It retrieves all edges a\ngiven vertex may have.  Query string:   tree    : the namespace;  format  : json|text [default: json]   Examples:    /v2/machine/warp0013?tree=leela::sandbox  N.B.: Remember to encode properly the query parameters!!!",
            "title": "/v2/kind/name"
        },
        {
            "location": "/user/http-interface/#v2kindnamelabel1label2labeln",
            "text": "This entrypoint issuse a  path  command. It retrieves all edges a\ngiven vertex may have. This is the same as the previous endpoint but\nyou can provide some labels to navigate further down in the graph.  Examples:    /v2/machine/warp0013/server/nic?tree=leela::sandbox  The above query issues the lql command:    using (leela::sandbox) path GUID -[server]> () -[nic]> ();  The GUID is the guid of  machine::warp0013 .  Query string   tree    : the namespace;  format  : json|text [default: json]",
            "title": "/v2/kind/name/label1/label2/.../labelN"
        },
        {
            "location": "/user/http-interface/#v2last",
            "text": "This entrypoint returns the last known value of a metric up to\n24h. Notice this is read from a cache and as such it may may return\neverything that exists in the database. That said, it is a good way to\nfetch data from multiple sources efficently.  Parameters:   attr    : The attribute to retrieve [eg:  cpu-0/cpu-idle ]. Notice you\n  can use also use glob syntax;  tree    : the namespace;  format  : json|text [default: json]   The following example retrieves everything from  machine::warp0013 .    /v2/last/machine/warp0013?tree=locaweb::sandbox&format=text&attr=*",
            "title": "/v2/last/*"
        },
        {
            "location": "/user/leela-query-language/",
            "text": "LEELA QUERY LANGUAGE\n\n\nLeela Query Language or simply LQL is the gateway to insert data or\nquery the database.\n\n\nThis document is divided into three sections. The first part describes\nthe structure of the language. The second one is graph manipulation\nand querying [edges and vertexes] and the final part is property\nmanipulation and querying.\n\n\nLQL\n\n\nThe language is built on the idea of commands with subcommands and\narguments. For instance, consider this example:\n\n\n  make (foo::bar)\n\n\n\n\nThe sintax above is used to create a vertex with name\n\nfoo::bar\n. There are commands that takes no arguments:\n\n\n  stat\n\n\n\n\nAnd there commands with subcommands like attr:\n\n\n  attr get 1d1a751c-622a-11e5-a7b4-efda49744bfe\n  ^    ^   ^\n  ^    ^   target/object\n  ^    subcommand\n  command\n\n\n\n\nThe language has a few types as well:\n\n\n  \"lql\"         : a string literal;\n  (double 42.0) : a double value [64 bits float type]\n  (int64 42)    : 64 bits signed integer;\n  (int32 42)    : 32 bits signed integer;\n  (uint64 42)   : 64 bits unsigned integer;\n  (uint32 42)   : 32 bits unsigned integer;\n  (bool true)   : boolean value;\n\n\n\n\nLastly, leela objects have namespaces. Namespaces completely isolates\nobjects and properties, so that you can use the same identifier in two\ndifferent namespaces without worries.\n\n\nEvery query must provide the namespace it is working on. Following is\na complete example of what a lql query looks like:\n\n\n  using (foo::bar) stat;\n  ^     ^          ^   ^\n  ^     ^          ^   query terminator\n  ^     ^          command + arguments\n  ^     ^\n  ^     namespace to use\n  ^\n  command\n\n\n\n\nEvery command starts with a \nusing\n command following by the namespace\nenclosed by parenthesis. The namespace is composed by two components,\nseparated from \n::\n. In the above case the first component is \nfoo\n\nand the second is \nbar\n. More about this in the \nNAMING\n section.\n\n\nNAMING\n\n\nThe identifiers in Leela are composed by two components. The idea\nbehind this is that the first component serves as category or class\nfor the name in question. Components are separated by \n::\n. Now,\nconsider the example:\n\n\n  machine::warp0013\n\n\n\n\nThe first component is \nmachine\n and the second is\n\nwarp0013\n. Similarly:\n\n\n  nic::00-01-02-03-04-05\n\n\n\n\nThis represents a network interface and its mac address.\n\n\nGRAPH MANIPULATION\n\n\nThere are two commands that deal with the graph structure:\n\n\n\n\nmake\n : create vertex and edges;\n\n\npath\n : navigate the graph;\n\n\nkill\n : destroy vertex and edges;\n\n\n\n\nMAKE\n\n\n  QUERY: make (kind::name);\n  REPLY: NAME\n\n\n\n\nCreates a new vertex identified by NAME. Is replies with a \nNAME\n\nmessage. For example:\n\n\n  > using (leela::sandbox) make (machine::warp0013);\n  < user  | tree    | kind    | name     | guid\n  < leela | sandbox | machine | warp0013 | cd8a5e22-622e-11e5-bb66-fb5334d472bc\n\n\n\n\nThe lines above need a little bit of explanation. The first line is\nthe LQL query. In the examples we will use the \n>\n character to\nidentify lines that are sent to the server. Following there is one or\nmore response lines, identified by the \n<\n character. More information\nabout the different types of answers at the final section of this\ndocument.\n\n\nLet's now create an edge:\n\n\n  QUERY: make GUID -[LABEL]> GUID;\n  REPLY: DONE\n\n\n\n\nThis command requires vertex ids instead of names. Then, you can link\ntwo vertex with a given label which can be later used to navigate\nthrough the graph. Let's see an example:\n\n\n  > using (leela::sandbox) make (machine::warp0013);\n  < user  | tree    | kind    | name     | guid\n  < leela | sandbox | machine | warp0013 | cd8a5e22-622e-11e5-bb66-fb5334d472bc\n\n  > using (leela::sandbox) make (nic::01-02-03-04-05);\n  < user  | tree    | kind | name           | guid\n  < leela | sandbox | nic  | 01-02-03-04-05 | 1d8bd666-6230-11e5-a3d6-7b6f71a2eebc\n\n  > using (leela::sandbox) make cd8a5e22-622e-11e5-bb66-fb5334d472bc -[nic]> 1d8bd666-6230-11e5-a3d6-7b6f71a2eebc;\n  < ()\n\n  > using (leela::sandbox) make cd8a5e22-622e-11e5-bb66-fb5334d472bc <[machine]- 1d8bd666-6230-11e5-a3d6-7b6f71a2eebc;\n  < ()\n\n\n\n\nThe first two queries just register the vertexes, nothing new\nhere. The last query is the one that creates the edge. Differently\nfrom vertexes, labels are just strings so there is no need to register\nthem. Labels are enclosed by \n-[]>\n, the reason for this is that that\nstring looks like an arrow. You can also change direction by using\n\n<[]-\n which creates an edge with the inverse direction.\n\n\nThe \nDONE\n reply is here represented by the \n()\n string because it has\nno payload.\n\n\nPATH\n\n\nThe path command allows you to navigate through the graph. Creating\nedges and navigating through them are very similar. As a matter effect\nthe syntax is almost the same:\n\n\nQUERY: path GUID\nQUERY: path GUID -[LABEL-GLOB]> ()...\nREPLY: PATH\n\n\n\nPath takes a variable number of arguments. It can be used with no\narguments in which case returns all edges a vertex may have. Or you\ncan provide some edges in which case the system will use information\nto navigate the structure. Examples:\n\n\n  > using (leela::sandbox) path cd8a5e22-622e-11e5-bb66-fb5334d472bc;\n  < label | guid\n  < nic   | 1d8bd666-6230-11e5-a3d6-7b6f71a2eebc\n\n  > using (leela::sandbox) path cd8a5e22-622e-11e5-bb66-fb5334d472bc -[n*]> ();\n  < label | guid\n  < nic   | 1d8bd666-6230-11e5-a3d6-7b6f71a2eebc\n\n  > using (leela::sandbox) path cd8a5e22-622e-11e5-bb66-fb5334d472bc -[foo]> ();\n  < ()\n\n\n\n\nThe first query retrieves all edges. The second one all edges that\nhave a label starting with n. The last one attempts to retrieve edges\nwith a \nfoo\n label, which does not exists, thus an empty reply.\n\n\nKILL\n\n\nKill commands are the dual of make commands. They share the same\nsyntax:\n\n\n  QUERY: kill GUID\n  QUERY: kill GUID -[LABEL]> ()...\n  REPLY: DONE\n\n\n\n\nThe second form destroy edges. The second form destroy vertexes and\nall information related [like properties and edges]. Sadly, deleting a\nvertex is not implemented.\n\n\nPROPERTY MANIPULATION\n\n\nVertexes may have properties and you can change or retrieve them using\nthe \nattr\n command. Properties comes in two flavors:\n\n\n\n\nkv: key-value property;\n\n\nts: time-series property;\n\n\n\n\nThe difference between the two is that the former is indexed by\ntime. You may think the \nkv\n property as a simple cell whereas the\n\nts\n as an array in which the indexes are timestamps.\n\n\nThere are four operations you can do with \nkv\n properties, namely\n\nput\n, \nget\n, \ndel\n and \nkls\n. The last one is used for enumerating\nthe attributes. The same commands can be used for \nts\n properties but\nthe last one which is \ntls\n instead. Next we provide details about\nevery one of them.\n\n\nATTR GET\n\n\nYou can use this command to retrieve both \nkv\n and \nts\n properties.\n\n\n  QUERY: attr get GUID \"NAME\" [WITH OPTIONS];\n  REPLY: K-ATTR\n\n\n\n\nThis syntax is used to fetch \nkv\n properties. Similarly:\n\n\n  QUERY: attr get GUID \"NAME\" [S:E]\n  REPLY: T-ATTR\n\n\n\n\nFetches \nts\n properties. The only difference is the last bit which\ncontains the start and finish of the time-series. For example:\n\n\n  > using (leela::sandbox) attr get cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foobar\" [0:3600];\n  < guid                                 | name   | series\n  < 4eb3de70-cb80-11e3-b4dc-0f48fe0268e8 | foobar | (1443043943.0, 19.95), (1443044003.0, 20.25), (1443044063.0, 16.5), (1443044123.0, 16.2334), (1443044183.0, 19.9333)\n\n\n\n\nFUNCTIONS\n\n\nThere are a few functions that can be applied to transform the\ndata. \nmap\n functions apply to each datapoint, which does not change\nthe size of the series. \nreduce\n functions on the other hand are\nblocking and consume all data before yielding a value\n[but you can use window functions to control how much data]. Following\na list of available functions:\n\n\n\n\nmap (+ N)\n              : for each datapoint, datapoint + N;\n\n\nmap (* N)\n              : for each datapoint, datapoint * N;\n\n\nmap (/ N)\n              : for each datapoint, datapoint / N;\n\n\nmap (- N)\n              : for each datapoint, datapoint - N;\n\n\nmap (N -)\n              : for each datapoint, N - datapoint;\n\n\nmap max\n                : for each datapoint yields the maximum found so far;\n\n\nmap min\n                : for each datapoint yields the mimimum found so far;\n\n\nmap (ewma R)\n           : for each point yields the exponential moving average using R as the alpha parameter;\n\n\nmap mean\n               : for each point yields the current mean value;\n\n\nmap count\n              : for each point yields the current size of the series;\n\n\nmap hmean\n              : for each point yields the harmonic mean value;\n\n\nmap abs\n                : absolute function [eg.: abs -9 = 9];\n\n\nmap ceil\n               : ceiling function [eg.: ceil 2.1 = 3];\n\n\nmap floor\n              : floor function [eg.: floor 2.9 = 2];\n\n\nmap round\n              : rounding function [eg.: round 2.5 = 3];\n\n\nmap truncate\n           : truncate function [ex.: truncate 2.3 = 2];\n\n\nmap sqrt\n               : square root function;\n\n\nmap (log R)\n            : logarithm base R;\n\n\nreduce (+)\n             : summation of the datapoints;\n\n\nreduce (*)\n             : product of the datapoints;\n\n\nreduce min\n             : the minimum value of the series;\n\n\nreduce max\n             : the maximum value of the series;\n\n\nreduce count\n           : the size of the series;\n\n\nreduce mean\n            : the mean value of the series;\n\n\nreduce hmean\n           : the harmonic mean value of the series;\n\n\nreduce (ewma R)\n        : the exponential moving average using R as the alpha parameter;\n\n\nfilter (> N)\n           : yields datapoints with value > N;\n\n\nfilter (< N)\n           : yields datapoints with value < N;\n\n\nfilter (>= N)\n          : yields datapoints with value >= N;\n\n\nfilter (<= N)\n          : yields datapoints with value <= N;\n\n\nfilter (N >)\n           : yields datapoints with N > value;\n\n\nfilter (N <)\n           : yields datapoints with N < value;\n\n\nfilter (N >=)\n          : yields datapoints with N >= value;\n\n\nfilter (N <=)\n          : yields datapoints with N <= value;\n\n\nfilter (N ==)\n          : yields datapoints with values == N;\n\n\nfilter (== N)\n          : yields datapoints with values == N;\n\n\nwindow N max\n           : groups N datapoints and yields the maximum;\n\n\nwindow N min\n           : groups N datapoints and yields the maximum;\n\n\nwindow N (*)\n           : groups N datapoints and yields the product of the series;\n\n\nwindow N (+)\n           : groups N datapoints and yields the summation of the series;\n\n\nwindow N (ewma R)\n      : groups N datapoints and yields the exponential moving average;\n\n\nwindow N mean\n          : groups N datapoints and yields the mean value;\n\n\nwindow N hmean\n         : groups N datapoints and yields the harmonic mean value;\n\n\ntime-window N max\n      : groups N seconds of data and yields the maximum;\n\n\ntime-window N min\n      : groups N seconds of data and yields the minimum;\n\n\ntime-window N (*)\n      : groups N seconds of data and yields the product of the series;\n\n\ntime-window N (+)\n      : groups N seconds of data and yields the summation of the series;\n\n\ntime-window N mean\n     : groups N seconds of data and yields then mean value;\n\n\ntime-window N hmean\n    : groups N seconds of data and yields then harmonic mean value;\n\n\ntime-window N (ewma R)\n : groups N seconds of data and yields the exponential moving average;\n\n\n\n\nATTR PUT\n\n\nUse this command to insert/modify data. \nKv\n properties looks like:\n\n\n  QUERY: attr put GUID \"NAME\" VALUE [WITH OPTIONS];\n  REPLY: ()\n\n\n\n\nThe value can be any value as described in the beginning of this\ndocument. Example:\n\n\n  > using (leela::sandbox) attr put cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foo\" \"bar\";\n  < ()\n\n\n\n\nNotice that put either inserts or updates the value. Now, for \nts\n properties:\n\n\n  QUERY: attr put GUID \"NAME\" [TIMESTAMP] VALUE;\n  REPLY: ()\n\n\n\n\nThe syntax is the same but the \n[TIMESTAMP]\n bit. This should contain\na timestamp, i.e, the number of seconds since Jan/01/1970. For instance:\n\n\n  > using (leela::sandbox) attr put cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foo\" [0] \"bar\";\n  < ()\n\n\n\n\nThis inserts the value \n\"bar\"\n at the given timestamp.\n\n\nOPTIONS\n\n\n\n\nttl:N sets an expiration time of N seconds for this data point. Example, an ttl of 60s:\n\n\n\n\n  > using (leela::sandbox) attr put cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foo\" [0] \"bar\" with ttl:60;\n  < ()\n\n\n\n\nATTR DEL\n\n\nUse this command to remove data. To remove \nkv\n properties:\n\n\n  QUERY: attr del GUID \"NAME\";\n  REPLY: ()\n\n\n\n\nSimilarly, to remove \nts\n properties:\n\n\n  QUERY: attr del GUID \"NAME\" [S:E]\n  REPLY: ()\n\n\n\n\nThe only difference is the timestamp bit. This is an interval, and all\nthe values from S to E [inclusive] will be removed.\n\n\nExamples:\n\n\n  > using (leela::sandbox) attr del cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foo\";\n  < ()\n  > using (leela::sandbox) attr del cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foo\" [0:3600];\n  < ()\n\n\n\n\nATTR KLS/TLS\n\n\nThis allows you to enumerate properties by name using a glob-like\nsyntax. The \nkls\n command is used to list \nkv\n\nproperties. Unsurprisingly, \ntls\n is used to list \nts\n properties.\n\n\n  QUERY: attr kls GUID \"NAME-GLOB\"\n  REPLY: NATTR\n\n  QUERY: attr tls GUID \"NAME-GLOB\"\n  REPLY: TATTR\n\n\n\n\nA few examples:\n\n\n  > using (leela::sandbox) attr kls cd8a5e22-622e-11e5-bb66-fb5334d472bc \"*\"\n  < guid`                                 | names\n  < cd8a5e22-622e-11e5-bb66-fb5334d472bc | cpu-idle | memory-free | swap-free ...\n\n  > using (leela::sandbox) attr tls cd8a5e22-622e-11e5-bb66-fb5334d472bc \"c*\"\n  < guid                                 | names\n  < cd8a5e22-622e-11e5-bb66-fb5334d472bc | cpu-idle",
            "title": "Leela query language"
        },
        {
            "location": "/user/leela-query-language/#leela-query-language",
            "text": "Leela Query Language or simply LQL is the gateway to insert data or\nquery the database.  This document is divided into three sections. The first part describes\nthe structure of the language. The second one is graph manipulation\nand querying [edges and vertexes] and the final part is property\nmanipulation and querying.",
            "title": "LEELA QUERY LANGUAGE"
        },
        {
            "location": "/user/leela-query-language/#lql",
            "text": "The language is built on the idea of commands with subcommands and\narguments. For instance, consider this example:    make (foo::bar)  The sintax above is used to create a vertex with name foo::bar . There are commands that takes no arguments:    stat  And there commands with subcommands like attr:    attr get 1d1a751c-622a-11e5-a7b4-efda49744bfe\n  ^    ^   ^\n  ^    ^   target/object\n  ^    subcommand\n  command  The language has a few types as well:    \"lql\"         : a string literal;\n  (double 42.0) : a double value [64 bits float type]\n  (int64 42)    : 64 bits signed integer;\n  (int32 42)    : 32 bits signed integer;\n  (uint64 42)   : 64 bits unsigned integer;\n  (uint32 42)   : 32 bits unsigned integer;\n  (bool true)   : boolean value;  Lastly, leela objects have namespaces. Namespaces completely isolates\nobjects and properties, so that you can use the same identifier in two\ndifferent namespaces without worries.  Every query must provide the namespace it is working on. Following is\na complete example of what a lql query looks like:    using (foo::bar) stat;\n  ^     ^          ^   ^\n  ^     ^          ^   query terminator\n  ^     ^          command + arguments\n  ^     ^\n  ^     namespace to use\n  ^\n  command  Every command starts with a  using  command following by the namespace\nenclosed by parenthesis. The namespace is composed by two components,\nseparated from  :: . In the above case the first component is  foo \nand the second is  bar . More about this in the  NAMING  section.",
            "title": "LQL"
        },
        {
            "location": "/user/leela-query-language/#naming",
            "text": "The identifiers in Leela are composed by two components. The idea\nbehind this is that the first component serves as category or class\nfor the name in question. Components are separated by  :: . Now,\nconsider the example:    machine::warp0013  The first component is  machine  and the second is warp0013 . Similarly:    nic::00-01-02-03-04-05  This represents a network interface and its mac address.",
            "title": "NAMING"
        },
        {
            "location": "/user/leela-query-language/#graph-manipulation",
            "text": "There are two commands that deal with the graph structure:   make  : create vertex and edges;  path  : navigate the graph;  kill  : destroy vertex and edges;   MAKE    QUERY: make (kind::name);\n  REPLY: NAME  Creates a new vertex identified by NAME. Is replies with a  NAME \nmessage. For example:    > using (leela::sandbox) make (machine::warp0013);\n  < user  | tree    | kind    | name     | guid\n  < leela | sandbox | machine | warp0013 | cd8a5e22-622e-11e5-bb66-fb5334d472bc  The lines above need a little bit of explanation. The first line is\nthe LQL query. In the examples we will use the  >  character to\nidentify lines that are sent to the server. Following there is one or\nmore response lines, identified by the  <  character. More information\nabout the different types of answers at the final section of this\ndocument.  Let's now create an edge:    QUERY: make GUID -[LABEL]> GUID;\n  REPLY: DONE  This command requires vertex ids instead of names. Then, you can link\ntwo vertex with a given label which can be later used to navigate\nthrough the graph. Let's see an example:    > using (leela::sandbox) make (machine::warp0013);\n  < user  | tree    | kind    | name     | guid\n  < leela | sandbox | machine | warp0013 | cd8a5e22-622e-11e5-bb66-fb5334d472bc\n\n  > using (leela::sandbox) make (nic::01-02-03-04-05);\n  < user  | tree    | kind | name           | guid\n  < leela | sandbox | nic  | 01-02-03-04-05 | 1d8bd666-6230-11e5-a3d6-7b6f71a2eebc\n\n  > using (leela::sandbox) make cd8a5e22-622e-11e5-bb66-fb5334d472bc -[nic]> 1d8bd666-6230-11e5-a3d6-7b6f71a2eebc;\n  < ()\n\n  > using (leela::sandbox) make cd8a5e22-622e-11e5-bb66-fb5334d472bc <[machine]- 1d8bd666-6230-11e5-a3d6-7b6f71a2eebc;\n  < ()  The first two queries just register the vertexes, nothing new\nhere. The last query is the one that creates the edge. Differently\nfrom vertexes, labels are just strings so there is no need to register\nthem. Labels are enclosed by  -[]> , the reason for this is that that\nstring looks like an arrow. You can also change direction by using <[]-  which creates an edge with the inverse direction.  The  DONE  reply is here represented by the  ()  string because it has\nno payload.  PATH  The path command allows you to navigate through the graph. Creating\nedges and navigating through them are very similar. As a matter effect\nthe syntax is almost the same:  QUERY: path GUID\nQUERY: path GUID -[LABEL-GLOB]> ()...\nREPLY: PATH  Path takes a variable number of arguments. It can be used with no\narguments in which case returns all edges a vertex may have. Or you\ncan provide some edges in which case the system will use information\nto navigate the structure. Examples:    > using (leela::sandbox) path cd8a5e22-622e-11e5-bb66-fb5334d472bc;\n  < label | guid\n  < nic   | 1d8bd666-6230-11e5-a3d6-7b6f71a2eebc\n\n  > using (leela::sandbox) path cd8a5e22-622e-11e5-bb66-fb5334d472bc -[n*]> ();\n  < label | guid\n  < nic   | 1d8bd666-6230-11e5-a3d6-7b6f71a2eebc\n\n  > using (leela::sandbox) path cd8a5e22-622e-11e5-bb66-fb5334d472bc -[foo]> ();\n  < ()  The first query retrieves all edges. The second one all edges that\nhave a label starting with n. The last one attempts to retrieve edges\nwith a  foo  label, which does not exists, thus an empty reply.  KILL  Kill commands are the dual of make commands. They share the same\nsyntax:    QUERY: kill GUID\n  QUERY: kill GUID -[LABEL]> ()...\n  REPLY: DONE  The second form destroy edges. The second form destroy vertexes and\nall information related [like properties and edges]. Sadly, deleting a\nvertex is not implemented.",
            "title": "GRAPH MANIPULATION"
        },
        {
            "location": "/user/leela-query-language/#property-manipulation",
            "text": "Vertexes may have properties and you can change or retrieve them using\nthe  attr  command. Properties comes in two flavors:   kv: key-value property;  ts: time-series property;   The difference between the two is that the former is indexed by\ntime. You may think the  kv  property as a simple cell whereas the ts  as an array in which the indexes are timestamps.  There are four operations you can do with  kv  properties, namely put ,  get ,  del  and  kls . The last one is used for enumerating\nthe attributes. The same commands can be used for  ts  properties but\nthe last one which is  tls  instead. Next we provide details about\nevery one of them.  ATTR GET  You can use this command to retrieve both  kv  and  ts  properties.    QUERY: attr get GUID \"NAME\" [WITH OPTIONS];\n  REPLY: K-ATTR  This syntax is used to fetch  kv  properties. Similarly:    QUERY: attr get GUID \"NAME\" [S:E]\n  REPLY: T-ATTR  Fetches  ts  properties. The only difference is the last bit which\ncontains the start and finish of the time-series. For example:    > using (leela::sandbox) attr get cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foobar\" [0:3600];\n  < guid                                 | name   | series\n  < 4eb3de70-cb80-11e3-b4dc-0f48fe0268e8 | foobar | (1443043943.0, 19.95), (1443044003.0, 20.25), (1443044063.0, 16.5), (1443044123.0, 16.2334), (1443044183.0, 19.9333)  FUNCTIONS  There are a few functions that can be applied to transform the\ndata.  map  functions apply to each datapoint, which does not change\nthe size of the series.  reduce  functions on the other hand are\nblocking and consume all data before yielding a value\n[but you can use window functions to control how much data]. Following\na list of available functions:   map (+ N)               : for each datapoint, datapoint + N;  map (* N)               : for each datapoint, datapoint * N;  map (/ N)               : for each datapoint, datapoint / N;  map (- N)               : for each datapoint, datapoint - N;  map (N -)               : for each datapoint, N - datapoint;  map max                 : for each datapoint yields the maximum found so far;  map min                 : for each datapoint yields the mimimum found so far;  map (ewma R)            : for each point yields the exponential moving average using R as the alpha parameter;  map mean                : for each point yields the current mean value;  map count               : for each point yields the current size of the series;  map hmean               : for each point yields the harmonic mean value;  map abs                 : absolute function [eg.: abs -9 = 9];  map ceil                : ceiling function [eg.: ceil 2.1 = 3];  map floor               : floor function [eg.: floor 2.9 = 2];  map round               : rounding function [eg.: round 2.5 = 3];  map truncate            : truncate function [ex.: truncate 2.3 = 2];  map sqrt                : square root function;  map (log R)             : logarithm base R;  reduce (+)              : summation of the datapoints;  reduce (*)              : product of the datapoints;  reduce min              : the minimum value of the series;  reduce max              : the maximum value of the series;  reduce count            : the size of the series;  reduce mean             : the mean value of the series;  reduce hmean            : the harmonic mean value of the series;  reduce (ewma R)         : the exponential moving average using R as the alpha parameter;  filter (> N)            : yields datapoints with value > N;  filter (< N)            : yields datapoints with value < N;  filter (>= N)           : yields datapoints with value >= N;  filter (<= N)           : yields datapoints with value <= N;  filter (N >)            : yields datapoints with N > value;  filter (N <)            : yields datapoints with N < value;  filter (N >=)           : yields datapoints with N >= value;  filter (N <=)           : yields datapoints with N <= value;  filter (N ==)           : yields datapoints with values == N;  filter (== N)           : yields datapoints with values == N;  window N max            : groups N datapoints and yields the maximum;  window N min            : groups N datapoints and yields the maximum;  window N (*)            : groups N datapoints and yields the product of the series;  window N (+)            : groups N datapoints and yields the summation of the series;  window N (ewma R)       : groups N datapoints and yields the exponential moving average;  window N mean           : groups N datapoints and yields the mean value;  window N hmean          : groups N datapoints and yields the harmonic mean value;  time-window N max       : groups N seconds of data and yields the maximum;  time-window N min       : groups N seconds of data and yields the minimum;  time-window N (*)       : groups N seconds of data and yields the product of the series;  time-window N (+)       : groups N seconds of data and yields the summation of the series;  time-window N mean      : groups N seconds of data and yields then mean value;  time-window N hmean     : groups N seconds of data and yields then harmonic mean value;  time-window N (ewma R)  : groups N seconds of data and yields the exponential moving average;   ATTR PUT  Use this command to insert/modify data.  Kv  properties looks like:    QUERY: attr put GUID \"NAME\" VALUE [WITH OPTIONS];\n  REPLY: ()  The value can be any value as described in the beginning of this\ndocument. Example:    > using (leela::sandbox) attr put cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foo\" \"bar\";\n  < ()  Notice that put either inserts or updates the value. Now, for  ts  properties:    QUERY: attr put GUID \"NAME\" [TIMESTAMP] VALUE;\n  REPLY: ()  The syntax is the same but the  [TIMESTAMP]  bit. This should contain\na timestamp, i.e, the number of seconds since Jan/01/1970. For instance:    > using (leela::sandbox) attr put cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foo\" [0] \"bar\";\n  < ()  This inserts the value  \"bar\"  at the given timestamp.  OPTIONS   ttl:N sets an expiration time of N seconds for this data point. Example, an ttl of 60s:     > using (leela::sandbox) attr put cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foo\" [0] \"bar\" with ttl:60;\n  < ()  ATTR DEL  Use this command to remove data. To remove  kv  properties:    QUERY: attr del GUID \"NAME\";\n  REPLY: ()  Similarly, to remove  ts  properties:    QUERY: attr del GUID \"NAME\" [S:E]\n  REPLY: ()  The only difference is the timestamp bit. This is an interval, and all\nthe values from S to E [inclusive] will be removed.  Examples:    > using (leela::sandbox) attr del cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foo\";\n  < ()\n  > using (leela::sandbox) attr del cd8a5e22-622e-11e5-bb66-fb5334d472bc \"foo\" [0:3600];\n  < ()  ATTR KLS/TLS  This allows you to enumerate properties by name using a glob-like\nsyntax. The  kls  command is used to list  kv \nproperties. Unsurprisingly,  tls  is used to list  ts  properties.    QUERY: attr kls GUID \"NAME-GLOB\"\n  REPLY: NATTR\n\n  QUERY: attr tls GUID \"NAME-GLOB\"\n  REPLY: TATTR  A few examples:    > using (leela::sandbox) attr kls cd8a5e22-622e-11e5-bb66-fb5334d472bc \"*\"\n  < guid`                                 | names\n  < cd8a5e22-622e-11e5-bb66-fb5334d472bc | cpu-idle | memory-free | swap-free ...\n\n  > using (leela::sandbox) attr tls cd8a5e22-622e-11e5-bb66-fb5334d472bc \"c*\"\n  < guid                                 | names\n  < cd8a5e22-622e-11e5-bb66-fb5334d472bc | cpu-idle",
            "title": "PROPERTY MANIPULATION"
        },
        {
            "location": "/devel/environment/",
            "text": "Leela is a multi-language project and getting the development\nenvironment right is not a trivial task. But fear not my friend, much\nhas been done to make this task simpler.\n\n\nThere are many ways of achieving this but in this document we have\ndecided to use docker \n1\n. Docker allows you to\ncreate and manage linux containers [well, it actually is much more\nthan that, but it is outside the scope of this document to go into\nfurther details], which we will use to create an isolated\nenvironment where we can compile, test and execute Leela.\n\n\nLets first clone the project:\n\n\n$ git clone git://github.com/locaweb/leela.git\n$ cd leela\n\n\n\n\nWe can now create the docker images we need. To see what images are\navailable, issue the command with no arguments.\n\n\n$ sudo ./automation/docker/makeimg.sh debian7.amd64\n\n\n\n\nNotice there are more images available. Just issue the same command\nwithout arguments in order to know what is available. For instance,\nthere are centos images available too.\n\n\nThis may take a while, but after it is done you should be able to see\na new container available:\n\n\n$ sudo docker images\nREPOSITORY             TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nleela/debian7-amd64    latest              2e01277ea2ca        6 hours ago         525.1 MB\n\n\n\nThis complete the foundation. From here it really depends on what you\nwant to do. Each component has its own set of dependencies and the\nfollowing sections details each one of them. However, without going\ninto much detail, this table summarizes what needs to be done:\n\n\n\n\n\n\n\n\ncomponent\n\n\nbootstrap-scripts\n\n\n\n\n\n\n\n\n\n\nlibleela\n\n\nzeromq-bootstrap.sh\n\n\n\n\n\n\nlibleela-python\n\n\nzeromq-bootstrap.sh\n\n\n\n\n\n\n\n\npython-bootstrap.sh\n\n\n\n\n\n\nlibleela-ruby\n\n\nzeromq-bootstrap.sh\n\n\n\n\n\n\n\n\nruby-bootstrap.sh\n\n\n\n\n\n\ncollectd\n\n\nzeromq-bootstrap.sh\n\n\n\n\n\n\n\n\ncollectd-bootstrap.sh\n\n\n\n\n\n\nwarpdrive\n\n\nzeromq-bootstrap.sh\n\n\n\n\n\n\n\n\nhaskell-bootstrap.sh\n\n\n\n\n\n\nblackbox\n\n\nzeromq-bootstrap.sh\n\n\n\n\n\n\n\n\njzmq-bootstrap.sh\n\n\n\n\n\n\n\n\nclojure-bootstrap.sh\n\n\n\n\n\n\nwarpgrep\n\n\nzeromq-bootstrap.sh\n\n\n\n\n\n\n\n\nhaskell-bootstrap.sh\n\n\n\n\n\n\n\n\nNotice that you must prepare the environment according to the next\nsection before compiling or testing the modules.\n\n\nPREPARE THE ENVIRONMENT\n\n\nThis section contains what must be done to prepare the environment for\ncompiling Leela. Each module gets its own section and its\nself-contained and the title matches the names in the following\nsections.\n\n\nLIBLEELA\n\n\ndebian7.amd64 $ /leela/automation/bootstrap/zeromq-bootstrap.sh\n\n\n\n\nLIBLEELA-PYTHON\n\n\ndebian7.amd64 $ /leela/automation/bootstrap/python-bootstrap.sh\ndebian7.amd64 $ /leela/automation/bootstrap/zeromq-bootstrap.sh\n\n\n\n\nLIBLEELA-RUBY\n\n\nIt is a gem instead of a package. The gem you should use is\n\nleela_ruby\n and is available at \nsrc/libs/ruby/leela_ruby\n.\n\n\nWARPDRIVE|WARPGREP\n\n\ndebian7.amd64 $ /leela/automation/bootstrap/zeromq-bootstrap.sh\ndebian7.amd64 $ /leela/automation/bootstrap/haskell-bootstrap.sh\n\n\n\n\nBLACKBOX\n\n\ndebian7.amd64 $ /leela/automation/bootstrap/zeromq-bootstrap.sh\ndebian7.amd64 $ /leela/automation/bootstrap/clojure-bootstrap.sh\ndebian7.amd64 $ /leela/automation/bootstrap/jzmq-bootstrap.sh\n\n\n\n\nCLIENT LIBRARIES\n\n\nThis section covers \nlibleela\n, \nlibleela-python\n and \nlibleela-ruby\n.\n\n\nThere is a \nmakefile\n on \nautomation/devel\n directory that has code to\ncompile the libraries on linux. This \nmakefile\n uses two importante\nvariables when building:\n\n\n\n\n\n\nbuildroot\n: the directory to store build generated\n  files. Defaults to \n/tmp/leela/build\n;\n\n\n\n\n\n\ndistroot\n: the installation directory. Defaults to\n  \n/tmp/leela/dist\n;\n\n\n\n\n\n\nSince these directories are not standard the linker will probably fail\nto find libraries. The same goes for Python. For this reason, there is\na simple script that defines a couple of environment variables that\nenables you to use this non standard path:\n\n\ndebian7.amd64 $ env distroot=/tmp/leela/dist \\\n                  /leela/automation/devel/envleela COMMAND\n\n\n\n\nJust keep in mind that you must use the very same \ndistroot\n to\nbuild leela components as often the components depends on each other.\n\n\nLIBLEELA\n\n\n$ sudo docker run \\\n         --rm \\\n         -i -t \\\n         -v $(pwd):/leela \\\n       leela/debian7-amd64 /bin/bash\ndebian7.amd64 $ /leela/automation/bootstrap/zeromq-bootstap.sh\ndebian7.amd64 $ make -C /leela/automation/devel compile.libleela\n\n\n\n\nThis should install files under the \ndistroot\n directory:\n\n\n$ ls -1F /tmp/leela/dist/lib/\nlibleela.so@\nlibleela.so.6@\nlibleela.so.6.4.1\nlibpoly1305aes.a\n\n\n\n\nLIBLEELA-PYTHON\n\n\ndebian7.amd64 $ make -C /leela/automation/devel compile.libleela-python\n\n\n\n\nThis installs the \npyleela\n python module:\n\n\ndebian7.amd64 $ /leela/automation/devel/envleela python2 -c 'import pyleela.lql; print(\"ok\");'\n\n\n\n\nLIBLEELA-RUBY\n\n\nTODO:fixme\n\n\nCOLLECTD\n\n\ndebian7.amd64 $ make -C /leela/automation/devel compile.collectd\n\n\n\n\nWhich must produce the write_leela shared library:\n\n\ndebian7.amd64 $ ls -1 /tmp/leela/lib/write_leela.so\n/tmp/leela/lib/write_leela.so\n\n\n\n\nCORE MODULES\n\n\nBLACKBOX\n\n\ndebian7.amd64 $ make -C /leela/automation/devel compile.blackbox\n\n\n\n\nWARPGREP\n\n\ndebian7.amd64 $ make -C /leela/automation/devel compile.warpgrep\n\n\n\n\nFRONTEND\n\n\nWARPDRIVE\n\n\ndebian7.amd64 $ make -C /leela/automation/devel compile.warpdrive\n\n\n\n\n\n\n\n\n\n\n\n\nhttp://docker.io\u00a0\n\u21a9",
            "title": "Environment"
        },
        {
            "location": "/devel/environment/#prepare-the-environment",
            "text": "This section contains what must be done to prepare the environment for\ncompiling Leela. Each module gets its own section and its\nself-contained and the title matches the names in the following\nsections.",
            "title": "PREPARE THE ENVIRONMENT"
        },
        {
            "location": "/devel/environment/#libleela",
            "text": "debian7.amd64 $ /leela/automation/bootstrap/zeromq-bootstrap.sh",
            "title": "LIBLEELA"
        },
        {
            "location": "/devel/environment/#libleela-python",
            "text": "debian7.amd64 $ /leela/automation/bootstrap/python-bootstrap.sh\ndebian7.amd64 $ /leela/automation/bootstrap/zeromq-bootstrap.sh",
            "title": "LIBLEELA-PYTHON"
        },
        {
            "location": "/devel/environment/#libleela-ruby",
            "text": "It is a gem instead of a package. The gem you should use is leela_ruby  and is available at  src/libs/ruby/leela_ruby .",
            "title": "LIBLEELA-RUBY"
        },
        {
            "location": "/devel/environment/#warpdrivewarpgrep",
            "text": "debian7.amd64 $ /leela/automation/bootstrap/zeromq-bootstrap.sh\ndebian7.amd64 $ /leela/automation/bootstrap/haskell-bootstrap.sh",
            "title": "WARPDRIVE|WARPGREP"
        },
        {
            "location": "/devel/environment/#blackbox",
            "text": "debian7.amd64 $ /leela/automation/bootstrap/zeromq-bootstrap.sh\ndebian7.amd64 $ /leela/automation/bootstrap/clojure-bootstrap.sh\ndebian7.amd64 $ /leela/automation/bootstrap/jzmq-bootstrap.sh",
            "title": "BLACKBOX"
        },
        {
            "location": "/devel/environment/#client-libraries",
            "text": "This section covers  libleela ,  libleela-python  and  libleela-ruby .  There is a  makefile  on  automation/devel  directory that has code to\ncompile the libraries on linux. This  makefile  uses two importante\nvariables when building:    buildroot : the directory to store build generated\n  files. Defaults to  /tmp/leela/build ;    distroot : the installation directory. Defaults to\n   /tmp/leela/dist ;    Since these directories are not standard the linker will probably fail\nto find libraries. The same goes for Python. For this reason, there is\na simple script that defines a couple of environment variables that\nenables you to use this non standard path:  debian7.amd64 $ env distroot=/tmp/leela/dist \\\n                  /leela/automation/devel/envleela COMMAND  Just keep in mind that you must use the very same  distroot  to\nbuild leela components as often the components depends on each other.",
            "title": "CLIENT LIBRARIES"
        },
        {
            "location": "/devel/environment/#libleela_1",
            "text": "$ sudo docker run \\\n         --rm \\\n         -i -t \\\n         -v $(pwd):/leela \\\n       leela/debian7-amd64 /bin/bash\ndebian7.amd64 $ /leela/automation/bootstrap/zeromq-bootstap.sh\ndebian7.amd64 $ make -C /leela/automation/devel compile.libleela  This should install files under the  distroot  directory:  $ ls -1F /tmp/leela/dist/lib/\nlibleela.so@\nlibleela.so.6@\nlibleela.so.6.4.1\nlibpoly1305aes.a",
            "title": "LIBLEELA"
        },
        {
            "location": "/devel/environment/#libleela-python_1",
            "text": "debian7.amd64 $ make -C /leela/automation/devel compile.libleela-python  This installs the  pyleela  python module:  debian7.amd64 $ /leela/automation/devel/envleela python2 -c 'import pyleela.lql; print(\"ok\");'",
            "title": "LIBLEELA-PYTHON"
        },
        {
            "location": "/devel/environment/#libleela-ruby_1",
            "text": "TODO:fixme",
            "title": "LIBLEELA-RUBY"
        },
        {
            "location": "/devel/environment/#collectd",
            "text": "debian7.amd64 $ make -C /leela/automation/devel compile.collectd  Which must produce the write_leela shared library:  debian7.amd64 $ ls -1 /tmp/leela/lib/write_leela.so\n/tmp/leela/lib/write_leela.so",
            "title": "COLLECTD"
        },
        {
            "location": "/devel/environment/#core-modules",
            "text": "",
            "title": "CORE MODULES"
        },
        {
            "location": "/devel/environment/#blackbox_1",
            "text": "debian7.amd64 $ make -C /leela/automation/devel compile.blackbox",
            "title": "BLACKBOX"
        },
        {
            "location": "/devel/environment/#warpgrep",
            "text": "debian7.amd64 $ make -C /leela/automation/devel compile.warpgrep",
            "title": "WARPGREP"
        },
        {
            "location": "/devel/environment/#frontend",
            "text": "",
            "title": "FRONTEND"
        },
        {
            "location": "/devel/environment/#warpdrive",
            "text": "debian7.amd64 $ make -C /leela/automation/devel compile.warpdrive      http://docker.io\u00a0 \u21a9",
            "title": "WARPDRIVE"
        },
        {
            "location": "/admin/cassandra/",
            "text": "CASSANDRA\n\n\nCassandra operation guide.\n\n\nCLUSTER INFO\n\n\n\n\nnodetool status\n          # lists members and its status\n\n\nnodetool tpstats\n         # queues should be close to zero; also you should see no errors\n\n\nnodetool compactionstats\n # should have very little activity\n\n\n\n\nUPGRADE\n\n\nRefer to regular cassandra upgrade guide.\n\n\nDISK USAGE\n\n\nIf disk free space is running low:\n\n\n\n\n$ ssh linda0001\n                     # any cassandra machine will do\n\n\nlinda0001 $ cqlsh -k leela\n          # provide the credentials as needed\n\n\nlinda0001 $ cql> truncate t_attr_NN\n # there are a table per month; pick one or more\n\n\n\n\nThese commands assume a health cluster. If that is not the case, use\n\ndrop table\n instead of truncate:\n\n\n\n\n$ ssh linda0001\n\n\nlinda0001 $ cqlsh -k leela\n\n\nlinda0001 $ cql> drop table t_attr_NN\n         # now wait a suitable amount of time\n\n\n$ ssh warp0013\n                                # any blackbox machine will do\n\n\nwarp0013 $ /etc/init.d/leela-blackbox restart\n # this will creates the missing table\n\n\n\n\nBACKUP\n\n\nAfter these commands the data is gone forever. If you want to backup\nit for whenever reason, before dropping or truncating the table:\n\n\n\n\n$ ssh linda0001\n\n\nlinda0001 $ nodetool snapshot -cf t_attr_NN leela\n # you need to do this on \nevery machine\n\n\n# backup the data: /var/lib/cassandra/data/leela/t_attr_NN-*/snapshots\n\n\nlinda0001 $ nodetool clearsnapshot\n                # you need to do this on \nevery machine\n\n\n\n\nREPAIR\n\n\nRepair is a regular process in cassandra that conciliates\ninformation. You need to run it regularly. Currently it repair only\nthe graph database and runs once a day:\n\n\n/etc/cron.d/cassandra-repair\n\n\n\n\nIt protects itself against simultaneous execution\n[so there is no harm to run manually]. The lock is keep at\n\n/tmp/cassandra-repair\n, in case the process get stuck.\n\n\nN.B.: Do not ever delete this file while there is a repair running. It\nis a costly operation and causes a considerable increase of load on\nthe cluster. Running multiple instances may cause severe performance\ndegradation.\n\n\nDISK FAILURE/MACHINE FAILURE\n\n\nIn the event of a disk/machine failure, replaces the disk and starts\nthe cassandra with the following flag:\n\n\n$ env JVM_OPTS=\"$JVM_OPTS -Dcassandra.replace_address=IP_OF_THE_DEAD_NODE\" /etc/init.d/cassandra start\n\n\n\n\nIf the IP is the same cassandra won't start without this flag. On the\nother hand, \nif the IP did change, you must not start cassandra\nwithout this flag\n. This is very important. Cassandra will bootstrap\na new node instead of replacing the old one. If you ever do this you\nwill have to decommission the dead node which will incur in much more\ndata moving around.",
            "title": "Cassandra"
        },
        {
            "location": "/admin/cassandra/#cassandra",
            "text": "Cassandra operation guide.",
            "title": "CASSANDRA"
        },
        {
            "location": "/admin/cassandra/#cluster-info",
            "text": "nodetool status           # lists members and its status  nodetool tpstats          # queues should be close to zero; also you should see no errors  nodetool compactionstats  # should have very little activity",
            "title": "CLUSTER INFO"
        },
        {
            "location": "/admin/cassandra/#upgrade",
            "text": "Refer to regular cassandra upgrade guide.",
            "title": "UPGRADE"
        },
        {
            "location": "/admin/cassandra/#disk-usage",
            "text": "If disk free space is running low:   $ ssh linda0001                      # any cassandra machine will do  linda0001 $ cqlsh -k leela           # provide the credentials as needed  linda0001 $ cql> truncate t_attr_NN  # there are a table per month; pick one or more   These commands assume a health cluster. If that is not the case, use drop table  instead of truncate:   $ ssh linda0001  linda0001 $ cqlsh -k leela  linda0001 $ cql> drop table t_attr_NN          # now wait a suitable amount of time  $ ssh warp0013                                 # any blackbox machine will do  warp0013 $ /etc/init.d/leela-blackbox restart  # this will creates the missing table   BACKUP  After these commands the data is gone forever. If you want to backup\nit for whenever reason, before dropping or truncating the table:   $ ssh linda0001  linda0001 $ nodetool snapshot -cf t_attr_NN leela  # you need to do this on  every machine  # backup the data: /var/lib/cassandra/data/leela/t_attr_NN-*/snapshots  linda0001 $ nodetool clearsnapshot                 # you need to do this on  every machine",
            "title": "DISK USAGE"
        },
        {
            "location": "/admin/cassandra/#repair",
            "text": "Repair is a regular process in cassandra that conciliates\ninformation. You need to run it regularly. Currently it repair only\nthe graph database and runs once a day:  /etc/cron.d/cassandra-repair  It protects itself against simultaneous execution\n[so there is no harm to run manually]. The lock is keep at /tmp/cassandra-repair , in case the process get stuck.  N.B.: Do not ever delete this file while there is a repair running. It\nis a costly operation and causes a considerable increase of load on\nthe cluster. Running multiple instances may cause severe performance\ndegradation.",
            "title": "REPAIR"
        },
        {
            "location": "/admin/cassandra/#disk-failuremachine-failure",
            "text": "In the event of a disk/machine failure, replaces the disk and starts\nthe cassandra with the following flag:  $ env JVM_OPTS=\"$JVM_OPTS -Dcassandra.replace_address=IP_OF_THE_DEAD_NODE\" /etc/init.d/cassandra start  If the IP is the same cassandra won't start without this flag. On the\nother hand,  if the IP did change, you must not start cassandra\nwithout this flag . This is very important. Cassandra will bootstrap\na new node instead of replacing the old one. If you ever do this you\nwill have to decommission the dead node which will incur in much more\ndata moving around.",
            "title": "DISK FAILURE/MACHINE FAILURE"
        },
        {
            "location": "/admin/consul/",
            "text": "CONSUL\n\n\nConsul operation guide. Consul is used for service discovery. Leela\ndiscover the machines by reading that information from consul.\n\n\nUPGRADE\n\n\nFirst upgrade the servers, one by one. After that you may upgrade the\nclients, again, one at a time.\n\n\nCLUSTER INFO\n\n\n\n\nconsul members\n                              # returns the cluster members and its status\n\n\ncurl http://localhost:8500/v1/status/peers\n  # current raft peers [usually three];\n\n\ncurl http://localhost:8500/v1/status/leader\n # \nmust\n return exactly one;\n\n\n\n\nADDING INSTANCES\n\n\n\n\nmake sure the directory \n/etc/consul/conf.d\n and the file\n   \n/etc/consul/config\n are properly configure. That file should come\n   from CFengine.\n\n\n/etc/init.d/consul start\n\n\n\n\nREMOVING INSTANCE\n\n\nSince the consul monitors a machine and all its services, if you ever\nremove an instance you must also remove all of its services. Follow\nthe procedure to stop and remove every service individually and then\nsimply stops consul:\n\n\n\n\n/etc/init.d/consul stop\n\n\n\n\nCONFIG FILES\n\n\n\n\n/etc/consul/config\n\n\n\n\nSERVICE FILES\n\n\nIf you ever change any of these files, issue \nconsul reload\n to apply\nthe changes.\n\n\n\n\n/etc/consul/conf.d/*.service\n\n\n\n\nBOOTSTRAPING A NEW CLUSTER\n\n\nAll machines have died, somehow! Then you need to put the cluster back\non:\n\n\n\n\nenv CONSUL_EXTRA_OPTS=\"-bootstrap\" /etc/init.d/consul start\n\n\n\n\nWait this instance to get back online. It should be the sole instance\nthus the leader. Now you can put the rest online normally\n[the dns should be working too].\n\n\n\n\n/etc/init.d/consul start",
            "title": "Consul"
        },
        {
            "location": "/admin/consul/#consul",
            "text": "Consul operation guide. Consul is used for service discovery. Leela\ndiscover the machines by reading that information from consul.",
            "title": "CONSUL"
        },
        {
            "location": "/admin/consul/#upgrade",
            "text": "First upgrade the servers, one by one. After that you may upgrade the\nclients, again, one at a time.",
            "title": "UPGRADE"
        },
        {
            "location": "/admin/consul/#cluster-info",
            "text": "consul members                               # returns the cluster members and its status  curl http://localhost:8500/v1/status/peers   # current raft peers [usually three];  curl http://localhost:8500/v1/status/leader  #  must  return exactly one;",
            "title": "CLUSTER INFO"
        },
        {
            "location": "/admin/consul/#adding-instances",
            "text": "make sure the directory  /etc/consul/conf.d  and the file\n    /etc/consul/config  are properly configure. That file should come\n   from CFengine.  /etc/init.d/consul start",
            "title": "ADDING INSTANCES"
        },
        {
            "location": "/admin/consul/#removing-instance",
            "text": "Since the consul monitors a machine and all its services, if you ever\nremove an instance you must also remove all of its services. Follow\nthe procedure to stop and remove every service individually and then\nsimply stops consul:   /etc/init.d/consul stop",
            "title": "REMOVING INSTANCE"
        },
        {
            "location": "/admin/consul/#config-files",
            "text": "/etc/consul/config",
            "title": "CONFIG FILES"
        },
        {
            "location": "/admin/consul/#service-files",
            "text": "If you ever change any of these files, issue  consul reload  to apply\nthe changes.   /etc/consul/conf.d/*.service",
            "title": "SERVICE FILES"
        },
        {
            "location": "/admin/consul/#bootstraping-a-new-cluster",
            "text": "All machines have died, somehow! Then you need to put the cluster back\non:   env CONSUL_EXTRA_OPTS=\"-bootstrap\" /etc/init.d/consul start   Wait this instance to get back online. It should be the sole instance\nthus the leader. Now you can put the rest online normally\n[the dns should be working too].   /etc/init.d/consul start",
            "title": "BOOTSTRAPING A NEW CLUSTER"
        },
        {
            "location": "/admin/install-leela/",
            "text": "This section contains information about how to install a Leela\ncluster. Is is divided into two sections. The first covers how to\ncreate the packages and the later how to install and configure the\npackages.\n\n\nThis document will use \ndebian-wheezy\n as the target platform and will\nmake use of the docker image that has been described in the\n\nenvironment\n section. If you haven't\ndone so refer to that document to get fetch the source code and create\nthe docker image.\n\n\nNow start the container. We will use it to build every single\ncomponent:\n\n\n$ docker run \\\n    -v .:/leela \\\n    --rm -i -t \\\n    leela/debian7-{arch} /bin/bash\n\n\n\n\nAlso this guide will install the local packages we have just\ngenerated. You are free to use any frontend you like but as we are\nusing local files we find it easier using \ngdebi\n.\n\n\n$ apt-get install gdebi\n\n\n\n\nLIBLEELA\n\n\nLibleela is the client library written in C. It is the base for the\nother libraries written in other languages and also contain the\npoly1305aes library. You will need it to built other leela components.\n\n\ndocker $ make -C /leela/pkg libleela.debian\n\n\n\n\nIt is likely to fail since there might be a few dependencies\nmissing. However those can be satisfied by the package manager. So\njust install those that are missing and try again.\n\n\nOn success the package will be available at:\n\n\ndocker $ ls -1 /leela/pkg/dist/debian7/{arch}/libleela/\nlibleela-dev_{major}.{minor}.{patch}-{build}_{arch}.deb\nlibleela_{major}.{minor}.{patch}-{build}.dsc\nlibleela_{major}.{minor}.{patch}-{build}.tar.gz\nlibleela_{major}.{minor}.{patch}-{build}_{arch}.changes\nlibleela_{major}.{minor}.{patch}-{build}_{arch}.deb\n\n\n\n\nLIBLEELA-PYTHON\n\n\ndocker $ make -C /leela/pkg libleela-python.debian\n\n\n\n\nLikewise, some dependencies may be missing. You must solve them and\ntry again. If everything went right, you should have the following\npackages:\n\n\ndocker $ ls -1 /leela/pkg/dist/debian7/{arch}/libleela-python\nlibleela-python_x.y.z-b.dsc\nlibleela-python_x.y.z-b.tar.gz\nlibleela-python_x.y.z-b_{arch}.changes\nlibleela-python_x.y.z-b_{arch}.deb\n\n\n\n\nWARPDRIVE\n\n\nThe warpdrive is the frontend of the Leela cluster. It is the service\nthat allows clients to store data and retrieve\ninformation.\n\n\ndocker $ make -C /leela/pkg leela-warpdrive.debian\n\n\n\n\nWhich should generate the following files:\n\n\ndocker $ ls -1 /leela/pkg/dist/debian7/{arch}/leela-warpdrive/\nleela-warpdrive_{major}.{minor}.{patch}-{build}.dsc\nleela-warpdrive_{major}.{minor}.{patch}-{build}.tar.gz\nleela-warpdrive_{major}.{minor}.{patch}-{build}_{arch}.changes\nleela-warpdrive_{major}.{minor}.{patch}-{build}_{arch}.deb\n\n\n\n\nCOLLECTD\n\n\nThis package provides a collectd write plugin. With this you can send\ncollectd metrics to Leela.\n\n\nAs usual, lets start preparing the environment. Notice that we use\ncollectd from source, since it is a bit unusual to compile modules.\n\n\nBLACKBOX\n\n\nThis is the storage backend used by the Leela cluster. It is used\ninternally and it the module that gives access to the cassandra\ncluster.\n\n\nIt is written in clojure which means you will need java\n[we recommend using Oracle's version, specially in production]. We\nwill use an Ubuntu PPA repository since debian has no java packages\nbut openjdk.\n\n\ndocker $ /leela/automation/bootstrap/clojure-bootstrap.sh\n\n\n\n\nAfter this script finishes you will have java and leiningen installed\nwhich allows us to build the package:\n\n\ndocker $ make -C /leela/pkg leela-blackbox.debian\n\n\n\n\nAfterthat you should have the following files:\n\n\ndocker $ ls -1 /leela/pkg/dist/debian7/{arch}/leela-blackbox/\nleela-blackbox_{major}.{minor}.{patch}-{build}.dsc\nleela-blackbox_{major}.{minor}.{patch}-{build}.tar.gz\nleela-blackbox_{major}.{minor}.{patch}-{build}_{arch}.changes\nleela-blackbox_{major}.{minor}.{patch}-{build}_{arch}.deb\n\n\n\n\nINSTALL\n\n\nBLACKBOX\n\n\nFirst install the package:\n\n\n$ gdebi install leela/pkg/leela-blackbox_{major}.{minor}.{patch}-{build}_{arch}.deb\n\n\n\n\nThen you must configure the daemon. The file that must be changed is\n\n/etc/default/leela-blackbox\n. It is self-documented, so we just\nhighlight the most important options:\n\n\nThe credentials to connect to cassandra cluster:\n\n\nLEELA_BLACKBOX_USERNAME=leela\nLEELA_BLACKBOX_PASSWORD=...\n\n\n\n\nThen the cassandra cluster endpoints. Use more than one, probably the\nseed nodes are a good option:\n\n\nLEELA_BLACKBOX_CASSANDRA=127.0.0.1,127.0.0.2\n\n\n\n\nWARPDRIVE\n\n\nFirst install the package:\n\n\n$ gdebi install leela/pkg/leela-warpdrive_{major}.{minor}.{patch}-{build}_{arch}.deb\n\n\n\n\nThen you must configure the daemon. The file you must change on debian\nis \n/etc/default/leela-warpdrive\n. It is self-documented so we just\ndescribe the most important options.\n\n\nThe following two variables defines the username and password used to\ntest this \nwarpdrive\n instance. Leela uses consul for auto-discovery\nand each service has a health checker associated. If the watchdog\nscript fails to execute the instance does not get announced.\n\n\nLEELA_WARPDRIVE_WATCHDOG_USER=\nLEELA_WARPDRIVE_WATCHDOG_PASS=\n\n\n\n\nAnother very important configuration is:\n\n\nLEELA_WARPDRIVE_ENDPOINT=\n\n\n\n\nIt defines network address of this instance that will be announced in\nconsul. You probably will need to change it since it defaults to\nlocal host.\n\n\nAfter the \n/etc/default/leela-warpdrive\n properly configured, you\nmay start the daemon:\n\n\n$ /etc/init.d/leela-warpdrive [start|stop|restart]\n\n\n\n\nNotice that it depends on a number of services to work correcly. Make\nsure you got these dependencies satisfied before making your cluster\navailable:\n\n\n\n\nredis [\ninstall guide\n]\n\n\nconsul [\ninstall guide\n]\n\n\nblackbox [\ninstall guide\n]",
            "title": "Install leela"
        },
        {
            "location": "/admin/install-leela/#libleela",
            "text": "Libleela is the client library written in C. It is the base for the\nother libraries written in other languages and also contain the\npoly1305aes library. You will need it to built other leela components.  docker $ make -C /leela/pkg libleela.debian  It is likely to fail since there might be a few dependencies\nmissing. However those can be satisfied by the package manager. So\njust install those that are missing and try again.  On success the package will be available at:  docker $ ls -1 /leela/pkg/dist/debian7/{arch}/libleela/\nlibleela-dev_{major}.{minor}.{patch}-{build}_{arch}.deb\nlibleela_{major}.{minor}.{patch}-{build}.dsc\nlibleela_{major}.{minor}.{patch}-{build}.tar.gz\nlibleela_{major}.{minor}.{patch}-{build}_{arch}.changes\nlibleela_{major}.{minor}.{patch}-{build}_{arch}.deb",
            "title": "LIBLEELA"
        },
        {
            "location": "/admin/install-leela/#libleela-python",
            "text": "docker $ make -C /leela/pkg libleela-python.debian  Likewise, some dependencies may be missing. You must solve them and\ntry again. If everything went right, you should have the following\npackages:  docker $ ls -1 /leela/pkg/dist/debian7/{arch}/libleela-python\nlibleela-python_x.y.z-b.dsc\nlibleela-python_x.y.z-b.tar.gz\nlibleela-python_x.y.z-b_{arch}.changes\nlibleela-python_x.y.z-b_{arch}.deb",
            "title": "LIBLEELA-PYTHON"
        },
        {
            "location": "/admin/install-leela/#warpdrive",
            "text": "The warpdrive is the frontend of the Leela cluster. It is the service\nthat allows clients to store data and retrieve\ninformation.  docker $ make -C /leela/pkg leela-warpdrive.debian  Which should generate the following files:  docker $ ls -1 /leela/pkg/dist/debian7/{arch}/leela-warpdrive/\nleela-warpdrive_{major}.{minor}.{patch}-{build}.dsc\nleela-warpdrive_{major}.{minor}.{patch}-{build}.tar.gz\nleela-warpdrive_{major}.{minor}.{patch}-{build}_{arch}.changes\nleela-warpdrive_{major}.{minor}.{patch}-{build}_{arch}.deb",
            "title": "WARPDRIVE"
        },
        {
            "location": "/admin/install-leela/#collectd",
            "text": "This package provides a collectd write plugin. With this you can send\ncollectd metrics to Leela.  As usual, lets start preparing the environment. Notice that we use\ncollectd from source, since it is a bit unusual to compile modules.",
            "title": "COLLECTD"
        },
        {
            "location": "/admin/install-leela/#blackbox",
            "text": "This is the storage backend used by the Leela cluster. It is used\ninternally and it the module that gives access to the cassandra\ncluster.  It is written in clojure which means you will need java\n[we recommend using Oracle's version, specially in production]. We\nwill use an Ubuntu PPA repository since debian has no java packages\nbut openjdk.  docker $ /leela/automation/bootstrap/clojure-bootstrap.sh  After this script finishes you will have java and leiningen installed\nwhich allows us to build the package:  docker $ make -C /leela/pkg leela-blackbox.debian  Afterthat you should have the following files:  docker $ ls -1 /leela/pkg/dist/debian7/{arch}/leela-blackbox/\nleela-blackbox_{major}.{minor}.{patch}-{build}.dsc\nleela-blackbox_{major}.{minor}.{patch}-{build}.tar.gz\nleela-blackbox_{major}.{minor}.{patch}-{build}_{arch}.changes\nleela-blackbox_{major}.{minor}.{patch}-{build}_{arch}.deb",
            "title": "BLACKBOX"
        },
        {
            "location": "/admin/install-leela/#install",
            "text": "",
            "title": "INSTALL"
        },
        {
            "location": "/admin/install-leela/#blackbox_1",
            "text": "First install the package:  $ gdebi install leela/pkg/leela-blackbox_{major}.{minor}.{patch}-{build}_{arch}.deb  Then you must configure the daemon. The file that must be changed is /etc/default/leela-blackbox . It is self-documented, so we just\nhighlight the most important options:  The credentials to connect to cassandra cluster:  LEELA_BLACKBOX_USERNAME=leela\nLEELA_BLACKBOX_PASSWORD=...  Then the cassandra cluster endpoints. Use more than one, probably the\nseed nodes are a good option:  LEELA_BLACKBOX_CASSANDRA=127.0.0.1,127.0.0.2",
            "title": "BLACKBOX"
        },
        {
            "location": "/admin/install-leela/#warpdrive_1",
            "text": "First install the package:  $ gdebi install leela/pkg/leela-warpdrive_{major}.{minor}.{patch}-{build}_{arch}.deb  Then you must configure the daemon. The file you must change on debian\nis  /etc/default/leela-warpdrive . It is self-documented so we just\ndescribe the most important options.  The following two variables defines the username and password used to\ntest this  warpdrive  instance. Leela uses consul for auto-discovery\nand each service has a health checker associated. If the watchdog\nscript fails to execute the instance does not get announced.  LEELA_WARPDRIVE_WATCHDOG_USER=\nLEELA_WARPDRIVE_WATCHDOG_PASS=  Another very important configuration is:  LEELA_WARPDRIVE_ENDPOINT=  It defines network address of this instance that will be announced in\nconsul. You probably will need to change it since it defaults to\nlocal host.  After the  /etc/default/leela-warpdrive  properly configured, you\nmay start the daemon:  $ /etc/init.d/leela-warpdrive [start|stop|restart]  Notice that it depends on a number of services to work correcly. Make\nsure you got these dependencies satisfied before making your cluster\navailable:   redis [ install guide ]  consul [ install guide ]  blackbox [ install guide ]",
            "title": "WARPDRIVE"
        },
        {
            "location": "/admin/packaging-leela/",
            "text": "This document contains information about how to create packages for\ndebian and centos. But make sure you follow the\n\npreparation steps\n\nas packaging depends on that.\n\n\nAfter you create the package it is available at\n\n/leela/pkg/dist\n. You can change using the \ndistroot\n variable.\n\n\nCLIENT LIBRARIES\n\n\nLIBLEELA\n\n\nDebian packages:\n\n\ndebian7.amd64 $ make -C /leela/pkg libleela.debian dist=debian7 arch=amd64\ndebian7.amd64 $ ls -1 /leela/pkg/dist/debian7/{arch}/libleela/\nlibleela-dev_{version}_{arch}.deb\nlibleela_{version}.dsc\nlibleela_{version}.tar.gz\nlibleela_{version}_{arch}.changes\nlibleela_{version}_{arch}.deb\n\n\n\n\nCentos packages:\n\n\ncentos6.amd64 $ make -C /leela/pkg libleela.centos dist=centos6 arch=amd64\ncentos6.amd64 $ ls -1 /leela/pkg/dist/centos6/{arch}/libleela/\nlibleela-{version}.src.rpm\nlibleela-{version}.{arch}.rpm\nlibleela-devel-{version}.{arch}.rpm\n\n\n\n\nLIBLEELA-PYTHON\n\n\nIt requires \nlibleela-devel\n installed to build properly.\n\n\nDebian packages:\n\n\ndebian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela_*.deb\ndebian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela-dev_*.deb\ndebian7.amd64 $ make -C /leela/pkg libleela-python.debian dist=debian7 arch=amd64\n\n\n\n\nCentos packages:\n\n\ncentos7.amd64 $ yum install /leela/pkg/dist/centos6/{arch}/libleela/libleela*.rpm\ncentos7.amd64 $ make -C /leela/pkg libleela-python.centos dist=centos6 arch=amd64\ncentos7.amd64 $ ls -1 /leela/pkg/dist/centos6/{arch}/libleela-python\nlibleela-python-{version}.src.rpm\nlibleela-python-{version}.{arch}.rpm\n\n\n\n\nLIBLEELA-RUBY\n\n\nThere is no package. Users should install use the gem\n\nleela_ruby\n. The gem is at \nsrc/libs/ruby/leela_ruby\n.\n\n\nCORE MODULES\n\n\nBLACKBOX\n\n\nIt requires \nlibleela-devel\n installed to build properly and only\ndebian packages are defined.\n\n\ndebian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela_*.deb\ndebian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela-dev_*.deb\ndebian7.amd64 $ make -C /leela/pkg leela-blackbox.debian dist=debian7 arch=amd64\n\n\n\n\nFRONTEND\n\n\nWARPDRIVE\n\n\nIt requires \nlibleela-devel\n installed to build properly and only\ndebian packages are defined.\n\n\ndebian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela_*.deb\ndebian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela-dev_*.deb\ndebian7.amd64 $ make -C /leela/pkg leela-warpdrive.debian dist=debian7 arch=amd64\ndebian7.amd64 $ ls -1 /leela/pkg/dist/debian7/amd64/leela-warpdrive/\nleela-warpdrive_{version}.dsc\nleela-warpdrive_{version}.tar.gz\nleela-warpdrive_{version}_{arch}.changes\nleela-warpdrive_{version}_{arch}.deb",
            "title": "Packaging leela"
        },
        {
            "location": "/admin/packaging-leela/#client-libraries",
            "text": "",
            "title": "CLIENT LIBRARIES"
        },
        {
            "location": "/admin/packaging-leela/#libleela",
            "text": "Debian packages:  debian7.amd64 $ make -C /leela/pkg libleela.debian dist=debian7 arch=amd64\ndebian7.amd64 $ ls -1 /leela/pkg/dist/debian7/{arch}/libleela/\nlibleela-dev_{version}_{arch}.deb\nlibleela_{version}.dsc\nlibleela_{version}.tar.gz\nlibleela_{version}_{arch}.changes\nlibleela_{version}_{arch}.deb  Centos packages:  centos6.amd64 $ make -C /leela/pkg libleela.centos dist=centos6 arch=amd64\ncentos6.amd64 $ ls -1 /leela/pkg/dist/centos6/{arch}/libleela/\nlibleela-{version}.src.rpm\nlibleela-{version}.{arch}.rpm\nlibleela-devel-{version}.{arch}.rpm",
            "title": "LIBLEELA"
        },
        {
            "location": "/admin/packaging-leela/#libleela-python",
            "text": "It requires  libleela-devel  installed to build properly.  Debian packages:  debian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela_*.deb\ndebian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela-dev_*.deb\ndebian7.amd64 $ make -C /leela/pkg libleela-python.debian dist=debian7 arch=amd64  Centos packages:  centos7.amd64 $ yum install /leela/pkg/dist/centos6/{arch}/libleela/libleela*.rpm\ncentos7.amd64 $ make -C /leela/pkg libleela-python.centos dist=centos6 arch=amd64\ncentos7.amd64 $ ls -1 /leela/pkg/dist/centos6/{arch}/libleela-python\nlibleela-python-{version}.src.rpm\nlibleela-python-{version}.{arch}.rpm",
            "title": "LIBLEELA-PYTHON"
        },
        {
            "location": "/admin/packaging-leela/#libleela-ruby",
            "text": "There is no package. Users should install use the gem leela_ruby . The gem is at  src/libs/ruby/leela_ruby .",
            "title": "LIBLEELA-RUBY"
        },
        {
            "location": "/admin/packaging-leela/#core-modules",
            "text": "",
            "title": "CORE MODULES"
        },
        {
            "location": "/admin/packaging-leela/#blackbox",
            "text": "It requires  libleela-devel  installed to build properly and only\ndebian packages are defined.  debian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela_*.deb\ndebian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela-dev_*.deb\ndebian7.amd64 $ make -C /leela/pkg leela-blackbox.debian dist=debian7 arch=amd64",
            "title": "BLACKBOX"
        },
        {
            "location": "/admin/packaging-leela/#frontend",
            "text": "",
            "title": "FRONTEND"
        },
        {
            "location": "/admin/packaging-leela/#warpdrive",
            "text": "It requires  libleela-devel  installed to build properly and only\ndebian packages are defined.  debian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela_*.deb\ndebian7.amd64 $ gdebi /leela/pkg/dist/debian7/{arch}/libleela/libleela-dev_*.deb\ndebian7.amd64 $ make -C /leela/pkg leela-warpdrive.debian dist=debian7 arch=amd64\ndebian7.amd64 $ ls -1 /leela/pkg/dist/debian7/amd64/leela-warpdrive/\nleela-warpdrive_{version}.dsc\nleela-warpdrive_{version}.tar.gz\nleela-warpdrive_{version}_{arch}.changes\nleela-warpdrive_{version}_{arch}.deb",
            "title": "WARPDRIVE"
        },
        {
            "location": "/admin/redis/",
            "text": "REDIS\n\n\nRedis operation guide. Redis is used to reduce the number of writes in\ncassandra and to reply \nlast\n queries.\n\n\nMAINTENANCE\n\n\n\n\n/etc/init.d/leela-redis watchdog-stop; sleep 60\n  # leela will no longer use this machine\n\n\n/etc/init.d/leela-redis stop\n                     # stops the service; now both redis are down\n\n\n# do your thing\n\n\n/etc/init.d/leela-redis start\n\n\n\n\nADDING INSTANCE\n\n\n\n\nmake sure the file \n/etc/consul/conf.d/redis.service\n exists and is\nproperly configured. This file should come from CFengine.\n\n\n/etc/init.d/leela-redis start\n\n\n\n\nREMOVING INSTANCE\n\n\n\n\n/etc/init.d/leela-redir watchdog-stop; sleep 60\n\n\n\n\nCLUSTER INFO\n\n\n\n\ncurl -s \"http://webleela.service.ita.consul.locaweb.com.br/v2?q=using%20(::)%20stat;&tree=locaweb::locaweb&format=json\" \\\n    | python -m json.tool | grep redis -A1\n\n\n\n\nEach of these endpoints must have two redis. The second redis must be\nlistening at \nport + 1\n. For instance, if redis bound to 6379, the\nsecond one must be listening at 6380.\n\n\nThis second redis must be a slave of the first in a master-slave\nreplication configuration. It is used to serve read queries to avoid\nblocking the master. As you know, redis is single threaded and we\ndon't want the reads negatively impacting the write path.",
            "title": "Redis"
        },
        {
            "location": "/admin/redis/#redis",
            "text": "Redis operation guide. Redis is used to reduce the number of writes in\ncassandra and to reply  last  queries.",
            "title": "REDIS"
        },
        {
            "location": "/admin/redis/#maintenance",
            "text": "/etc/init.d/leela-redis watchdog-stop; sleep 60   # leela will no longer use this machine  /etc/init.d/leela-redis stop                      # stops the service; now both redis are down  # do your thing  /etc/init.d/leela-redis start",
            "title": "MAINTENANCE"
        },
        {
            "location": "/admin/redis/#adding-instance",
            "text": "make sure the file  /etc/consul/conf.d/redis.service  exists and is\nproperly configured. This file should come from CFengine.  /etc/init.d/leela-redis start",
            "title": "ADDING INSTANCE"
        },
        {
            "location": "/admin/redis/#removing-instance",
            "text": "/etc/init.d/leela-redir watchdog-stop; sleep 60",
            "title": "REMOVING INSTANCE"
        },
        {
            "location": "/admin/redis/#cluster-info",
            "text": "curl -s \"http://webleela.service.ita.consul.locaweb.com.br/v2?q=using%20(::)%20stat;&tree=locaweb::locaweb&format=json\" \\\n    | python -m json.tool | grep redis -A1   Each of these endpoints must have two redis. The second redis must be\nlistening at  port + 1 . For instance, if redis bound to 6379, the\nsecond one must be listening at 6380.  This second redis must be a slave of the first in a master-slave\nreplication configuration. It is used to serve read queries to avoid\nblocking the master. As you know, redis is single threaded and we\ndon't want the reads negatively impacting the write path.",
            "title": "CLUSTER INFO"
        }
    ]
}